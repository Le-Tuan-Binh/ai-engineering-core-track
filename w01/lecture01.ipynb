{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Import the library\n",
    "\n",
    "This section imports all required libraries and modules used throughout the notebook.\n",
    "\n",
    "It includes environment variable loading, website scraping utilities, Markdown rendering for Jupyter Notebook, and the OpenAI client."
   ],
   "id": "bfdb01950576110a"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from scraper_v1 import get_website_contents\n",
    "from IPython.display import Markdown, display"
   ],
   "id": "9bb58b68c94b34a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Connecting to OpenAI\n",
    "\n",
    "This section loads environment variables from the `.env` file and connects to OpenAI using the `API_KEY`.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Create a `.env` file in your project directory.\n",
    "\n",
    "2. Add the following line to the file, replacing the value with your actual OpenAI API key `OPENAI_API_KEY=sk-xxxxxxx`\n",
    "\n",
    "3. Run the script below to load and verify the API key."
   ],
   "id": "3c261577c46565a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "def validate_api_key(key: str):\n",
    "    if not key:\n",
    "        raise ValueError(\n",
    "            \"❌ No API key was found, please be sure to add your key to the .env file\"\n",
    "        )\n",
    "    if not key.startswith(\"sk-proj-\"):\n",
    "        raise ValueError(\n",
    "            \"⚠️ API key was found, but it doesn't start AIz\"\n",
    "        )\n",
    "    if key.strip() != key:\n",
    "        raise ValueError(\n",
    "            \"⚠️ API key has leading or trailing whitespace, please remove them.\"\n",
    "        )\n",
    "    print(\"✅ API key has found and looks good!\")\n",
    "\n",
    "validate_api_key(api_key)\n"
   ],
   "id": "79f4724ca97773c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Quick Preview",
   "id": "3cfb07ae9478277a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare the message\n",
    "message = \"Hello, Chat GPT! This is my first ever message to you! Hi!\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": message\n",
    "    }\n",
    "]"
   ],
   "id": "5ba35d81bb81985a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "openai = OpenAI()\n",
    "\n",
    "# Call the model to generate a response\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Extract the model's reply\n",
    "reply = response.choices[0].message.content"
   ],
   "id": "fe558489971b379e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User message\n",
    "message"
   ],
   "id": "1e87ad7bbec6d368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model message\n",
    "reply"
   ],
   "id": "94b5031826882ee5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Collect the content\n",
    "\n",
    "This section retrieves the raw text content from the specified website using the `get_website_contents` function.\n",
    "\n",
    "It sends a request to the target URL, collects the returned data, and prints it so that you can inspect what the model will analyze in later steps."
   ],
   "id": "8e0af0b91370f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "content = get_website_contents(\"https://example.com/\")",
   "id": "287f4b53ad3b7edd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "content",
   "id": "a998744397c973bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Types of prompts\n",
    "\n",
    "Large Language models like ChatGPT are trained to process requests using a standardized prompt structure to ensure consistency and accuracy in their responses.\n",
    "\n",
    "There are two main types of prompts\n",
    "\n",
    "- **System prompt**: instructions for the system that defines the task scope, operating context, the model’s role, and the response style it should maintain throughout the interaction.\n",
    "\n",
    "- **User prompt**: content provided directly by the user, this serves as the primary input signal that the model analyzes to generate an appropriate response.\n",
    "\n",
    "Choosing the right prompts and clearly defining both system and user instructions is crucial for obtaining accurate, relevant, and context-aware responses from the model."
   ],
   "id": "7f95f24d402243de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define system prompt",
   "id": "c8f767d4f5842ddb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define our system prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a highly technical assistant that analyzes the content of a website.\n",
    "Identify the main topics, summarize key information, and highlight any important updates or announcements.\n",
    "Ignore navigation menus, ads, or unrelated boilerplate text.\n",
    "Provide your response clearly in markdown. Do not wrap the markdown in a code block, respond directly with markdown.\n",
    "\"\"\""
   ],
   "id": "d53a4d0fc9b45ab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define user prompt",
   "id": "9f61cf1577060d0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news, announcements, or updates, summarize these as well.\n",
    "\"\"\""
   ],
   "id": "eef36c15beee63cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Messages\n",
    "\n",
    "When using the OpenAI API, input data must follow a standard message structure.\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message\"}\n",
    "]\n",
    "```\n",
    "\n",
    "This structure allows the model to distinguish between system context and user instructions, enabling it to generate accurate and context-aware responses."
   ],
   "id": "d274b74f1647a595"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ],
   "id": "88769e104756886c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Send the request to the OpenAI API\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")"
   ],
   "id": "2817d0fc92d1d0fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract the model's reply\n",
    "reply = response.choices[0].message.content\n",
    "reply"
   ],
   "id": "5be8a654babc9eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Build messages using a function\n",
    "\n",
    "This function automatically constructs the messages structure in the format required by the API.\n",
    "\n",
    "Simply pass the content to the function, which then combines it with the predefined system and user prompts to generate a complete message payload ready for the OpenAI API."
   ],
   "id": "cc05492544cdcff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build messages using a function\n",
    "def messages_for(raw_content):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt + raw_content}\n",
    "    ]"
   ],
   "id": "f8f09d0e90e6a7e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "At this point, we can preview how the message looks when generated using sample content.",
   "id": "2d0006f7676f9018"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "messages_for(content)",
   "id": "cc7bd7ac37f49bc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The API for OpenAI is very simple\n",
    "\n",
    "The OpenAI API is designed to be straightforward.\n",
    "\n",
    "By providing a structured list of messages, you can send user input and system instructions to the model, and receive context-aware, high-quality responses."
   ],
   "id": "f1139ca9b3b0ff01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Call the OpenAI API\n",
    "\n",
    "This function get the content and sends it to the OpenAI API using the `messages_for` function.\n",
    "\n",
    "The model processes the input and returns a concise, context-aware summary."
   ],
   "id": "ea8f81edd654b795"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the content and send it to the OpenAI API\n",
    "def summarize(url):\n",
    "    raw_content = get_website_contents(url)\n",
    "    raw_response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(raw_content)\n",
    "    )\n",
    "    return raw_response.choices[0].message.content"
   ],
   "id": "7d222ab48e8fed5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summarize(\"https://example.com/\")",
   "id": "6a44b9161f49ae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Display the response in nice format\n",
    "\n",
    "The `display_result` function wraps the response in Markdown formatting, making it easier to read directly in Jupyter Notebook."
   ],
   "id": "34beea92ea5fb80e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Output\n",
    "def display_result(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ],
   "id": "9604198dfe8fdd70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display_result(\"https://example.com\")",
   "id": "99557f52b714eac2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display_result(\"https://cnn.com\")",
   "id": "8a0217487bcd0d11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You may notice that if you try `display_summary(\"https://openai.com\")`, it doesn't work! That's because this content has a fancy that uses Javascript.\n",
    "\n",
    "So you need to use **Selenium**, which is a hugely popular library that runs a browser behind the scenes, renders the page, and allows you to query it.\n",
    "\n",
    "I have the version use the **Selenium** in **scraper_v2.py**, you can try with this for `display_result(\"https://openai.com\")`"
   ],
   "id": "aab6258be2e4bbce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display_result(\"https://openai.com\")",
   "id": "b9cf9a1febf7c8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summarization with LLMs\n",
    "\n",
    "In this exercise, we explore how to call the OpenAI API of a **Frontier Model** to perform a classic **summarization task**.\n",
    "\n",
    "Summarization is widely applicable in real-world, for example:\n",
    "\n",
    "- Summarizing news articles\n",
    "- Summarizing financial performance reports\n",
    "\n",
    "You can prototype your own solution to see how AI can help your real-world workflows."
   ],
   "id": "8d61dd4144cbdebc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"system prompt\"\n",
    "user_prompt = \"\"\"\n",
    "    user prompt\n",
    "\"\"\""
   ],
   "id": "30528ef76eb98546",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2: Build the messages list\n",
    "\n",
    "messages = []"
   ],
   "id": "411fe4fad5de9dd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 3: Call OpenAI API\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "openai = OpenAI()\n",
    "\n",
    "# Call the model to generate a response\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages\n",
    ")"
   ],
   "id": "1dabb4d5e761007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4: Print the result\n",
    "\n",
    "# Extract the model's reply\n",
    "reply = response.choices[0].message.content\n",
    "\n",
    "print(reply)"
   ],
   "id": "4158269c88c9bec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summarization of Emails\n",
    "\n",
    "In this section, we will use the same approach to summarize email content and generate a short, appropriate subject line for the email. This is a common commercial application in email tools."
   ],
   "id": "8dde4535192e0cdb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create your prompts",
   "id": "191ff7725e76a4e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are a helpful assistant that summarizes emails and suggests concise subject lines.\"\n",
    "user_prompt = \"\"\"\n",
    "Here is the content of an email:\n",
    "[Paste the email content here]\n",
    "\n",
    "Please provide a short and clear subject line for this email.\n",
    "\"\"\""
   ],
   "id": "c7fdf37e623aebdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build the function",
   "id": "a6bf0c06e6abb82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Build system and user prompts for summarizing an email.\n",
    "\n",
    "Args:\n",
    "    email_text (str): The content of the email.\n",
    "\n",
    "Returns:\n",
    "    tuple[str, str]: (system_prompt, user_prompt)\n",
    "\"\"\"\n",
    "def build_email_prompts(email_text: str) -> tuple[str, str]:\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        You are a helpful assistant that summarizes emails and suggests concise subject lines.\n",
    "        Provide your response clearly in markdown. Not wrap the markdown in a code block, respond directly with markdown.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Here is the content of an email:\n",
    "        {email_text}\n",
    "\n",
    "        Please provide a short and clear subject line for this email.\n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt"
   ],
   "id": "1e199ca4b8ea53a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build the messages list",
   "id": "632d47f0e428287e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ],
   "id": "319f8897eaaeea52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Call OpenAI API",
   "id": "535cc00136decec5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages\n",
    ")"
   ],
   "id": "d54255f5cee183db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## See the output",
   "id": "f4b2805d93390e8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "subject_line = response.choices[0].message.content\n",
    "print(subject_line)"
   ],
   "id": "d5d090d36154318e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summarization of emails",
   "id": "10952ba220edc70f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "\"\"\"\n",
    "Build system and user prompts for summarizing an email.\n",
    "\n",
    "Args:\n",
    "    email_text (str): The content of the email.\n",
    "\n",
    "Returns:\n",
    "    tuple[str, str]: (system_prompt, user_prompt)\n",
    "\"\"\"\n",
    "def build_email_prompts(email_text: str) -> tuple[str, str]:\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant that summarizes emails.\n",
    "    Provide your response in Markdown format, including:\n",
    "        - Email Content section with the full email\n",
    "        - Suggested Subject Line section with the short, clear subject\n",
    "    Do not wrap the Markdown in a code block.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Here is the content of an email:\n",
    "        {email_text}\n",
    "\n",
    "        Please provide a short and clear subject line for this email.\n",
    "    \"\"\"\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Summarizes the content of an email and suggests a short subject line.\n",
    "\n",
    "```\n",
    "Args:\n",
    "    email_content (str): The full text of the email.\n",
    "\n",
    "Returns:\n",
    "    str: Suggested concise subject line.\n",
    "\"\"\"\n",
    "def summarize_email(email_content: str):\n",
    "\n",
    "    system_prompt, user_prompt = build_email_prompts(email_content)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    subject_line = response.choices[0].message.content\n",
    "\n",
    "    return Markdown(subject_line)"
   ],
   "id": "125fafb384d59c1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing with the value",
   "id": "f3f0756386a532d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "email_text = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "I hope this message finds you well. As part of our quarterly review, I've compiled the Q3 financial report and attached it to this email. The report includes detailed information on revenue streams, expenditure breakdowns, and key performance indicators across all departments.\n",
    "\n",
    "Please pay special attention to the marketing and R&D sections as they highlight ongoing projects and budget allocations for next quarter. We have also included an analysis of market trends and competitor activities that may impact our strategic planning.\n",
    "\n",
    "Feel free to review the summary charts and financial tables at the beginning of each section, which provide a quick overview of the main points. If you have any questions, suggestions, or need additional clarifications, do not hesitate to reach out to me or the finance team directly.\n",
    "\n",
    "Thank you for your attention and your continued hard work. Looking forward to discussing these results in our upcoming team meeting next week.\n",
    "\n",
    "Best regards,\n",
    "Le Tuan Binh\n",
    "\"\"\"\n",
    "\n",
    "summarize_email(email_text)"
   ],
   "id": "b3cef4a8fce59cab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
